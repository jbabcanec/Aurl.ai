# Stage 1: Base Training (No Augmentation)
# Fast, reliable training on clean data to establish baseline

model:
  mode: "transformer"  # Simple, stable transformer mode
  d_model: 256         # Good balance of capacity and speed
  n_layers: 4          # Moderate depth for learning
  n_heads: 4           # Standard attention heads
  dropout: 0.1
  max_sequence_length: 512  # Manageable sequence length
  vocab_size: 774      # Full musical vocabulary
  
  # VAE specific (not used in stage 1 but defined)
  latent_dim: 128
  encoder_layers: 3
  decoder_layers: 3
  beta: 1.0
  
  # Attention configuration (only parameters model accepts)
  attention_type: "hierarchical"
  local_window_size: 128
  global_window_size: 64
  sliding_window_size: 256

training:
  batch_size: 8        # Moderate batch size for stability
  learning_rate: 3.0e-4  # Conservative learning rate
  num_epochs: 20       # Sufficient for base learning
  warmup_steps: 500    # Gradual warmup
  weight_decay: 1.0e-5
  gradient_clip_norm: 1.0
  accumulate_grad_batches: 1
  
  # Checkpointing
  save_every_n_epochs: 5
  keep_best_n_checkpoints: 3
  
  # Early stopping
  early_stopping: true
  patience: 8
  min_delta: 1.0e-4
  
  # Scheduling
  scheduler: "cosine"
  min_learning_rate: 1.0e-6
  
  # Mixed precision - disabled for MPS compatibility
  mixed_precision: false
  
  # Loss weights
  reconstruction_weight: 1.0
  kl_weight: 1.0
  adversarial_weight: 0.0  # No GAN in stage 1

data:
  sequence_length: 512     # Manageable length for base training
  overlap: 128
  min_sequence_length: 64
  
  # Preprocessing
  normalize_velocity: true
  quantize_timing: true
  quantization_level: 1.0
  
  # NO AUGMENTATION in Stage 1 - use clean cached data
  augmentation: false
  
  # Caching
  cache_processed_data: true
  cache_size_gb: 3
  num_workers: 4

experiment:
  name: "stage1_base_training"
  group: "aurl_training_pipeline"
  tags: ["stage1", "base", "no_augmentation", "transformer"]
  notes: "Stage 1: Base training on clean data, no augmentation"
  
  # Tracking
  use_wandb: false
  use_tensorboard: true
  tensorboard_log_dir: "logs/tensorboard/stage1"
  
  # Logging
  log_every_n_steps: 25
  save_samples_every_n_epochs: 5

system:
  device: "auto"
  gpu_ids: [0]
  num_workers: 4
  pin_memory: true
  
  # Paths
  data_dir: "data/raw"
  cache_dir: "data/cache"
  output_dir: "outputs"
  log_dir: "logs"
  
  # Reproducibility
  seed: 42
  deterministic: true
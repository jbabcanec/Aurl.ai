"""
Comprehensive test suite for Phase 4.2 Logging System.

This test verifies:
1. Enhanced logger initialization and configuration
2. Structured logging format (exact gameplan specification)
3. TensorBoard integration functionality
4. Weights & Biases experiment tracking
5. Real-time dashboard visualization
6. Experiment tracking and comparison
7. Data usage tracking with augmentation details
8. Training progress estimation (ETA)
9. Console notifications and alerts
10. Anomaly detection and reporting
11. Log rotation and compression
12. Musical quality metrics tracking
"""

import sys
import torch
import numpy as np
from pathlib import Path
import tempfile
import shutil
import json
import time
from datetime import datetime, timedelta
from unittest.mock import Mock, patch
import logging

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.training.core.training_logger import (
    EnhancedTrainingLogger, StructuredFormatter
)
from src.training.core.experiment_tracker import (
    ComprehensiveExperimentTracker, DataUsageInfo, EpochSummary
)
from src.training.monitoring.tensorboard_logger import TensorBoardLogger
from src.training.monitoring.realtime_dashboard import RealTimeDashboard, ConsoleLogger
from src.training.monitoring.wandb_integration import WandBIntegration
from src.utils.base_logger import setup_logger

logger = setup_logger(__name__)


def test_structured_logging_format():
    """Test structured logging format matches gameplan exactly."""
    print("ğŸ§ª Testing Structured Logging Format")
    print("-" * 40)
    
    try:
        # Test StructuredFormatter
        formatter = StructuredFormatter()
        
        # Create a log record
        record = logging.LogRecord(
            name="aurl.training",
            level=logging.INFO,
            pathname="test.py",
            lineno=100,
            msg="Test message",
            args=(),
            exc_info=None
        )
        
        # Format the record
        formatted = formatter.format(record)
        
        # Check format: [YYYY-MM-DD HH:MM:SS.mmm] [LEVEL] [MODULE] Message
        assert formatted.startswith("["), f"Should start with [, got: {formatted}"
        assert "] [INFO] [" in formatted, f"Should have level and module, got: {formatted}"
        assert formatted.endswith("Test message"), f"Should end with message, got: {formatted}"
        
        # Check timestamp format
        parts = formatted.split("] [")
        timestamp_part = parts[0][1:]  # Remove leading [
        
        # Verify timestamp has milliseconds
        assert "." in timestamp_part, f"Timestamp should have milliseconds: {timestamp_part}"
        assert len(timestamp_part.split(".")[-1]) == 3, f"Should have 3 digit milliseconds"
        
        print(f"   âœ… Structured format correct: {formatted}")
        print(f"   âœ… Timestamp includes milliseconds")
        print(f"   âœ… Level and module included")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_enhanced_logger_initialization(test_experiment_dir):
    """Test EnhancedTrainingLogger initialization."""
    print("\nğŸ§ª Testing Enhanced Logger Initialization")
    print("-" * 40)
    
    try:
        # Create logger with all features enabled
        enhanced_logger = EnhancedTrainingLogger(
            experiment_name="test_experiment",
            save_dir=test_experiment_dir,
            model_config={"d_model": 512, "n_layers": 12},
            training_config={"batch_size": 32, "learning_rate": 1e-4},
            data_config={"dataset_size": 10000},
            enable_tensorboard=True,
            enable_dashboard=False,  # Disable GUI for testing
            enable_wandb=False,  # Disable W&B for unit tests
            log_level="INFO"
        )
        
        # Verify components initialized
        assert enhanced_logger.experiment_tracker is not None, "Experiment tracker should be initialized"
        assert enhanced_logger.tensorboard_logger is not None, "TensorBoard logger should be initialized"
        assert enhanced_logger.console_logger is not None, "Console logger should be initialized"
        assert enhanced_logger.structured_logger is not None, "Structured logger should be initialized"
        
        print(f"   âœ… Enhanced logger initialized")
        print(f"   âœ… Experiment ID: {enhanced_logger.experiment_id}")
        print(f"   âœ… Save directory: {enhanced_logger.save_dir}")
        
        # Check log file creation
        log_dir = enhanced_logger.save_dir / "logs"
        assert log_dir.exists(), "Logs directory should be created"
        
        log_files = list(log_dir.glob("*.log"))
        assert len(log_files) > 0, "Log file should be created"
        
        print(f"   âœ… Log file created: {log_files[0].name}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_batch_logging():
    """Test batch-level logging with exact format."""
    print("\nğŸ§ª Testing Batch-Level Logging")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="test_batch_logging",
                save_dir=Path(temp_dir),
                model_config={"d_model": 256},
                training_config={"batch_size": 16},
                data_config={"dataset_size": 1000},
                enable_tensorboard=False,
                enable_dashboard=False,
                enable_wandb=False
            )
            
            # Start training and epoch
            enhanced_logger.start_training(total_epochs=10)
            enhanced_logger.start_epoch(epoch=1, total_batches=50)
            
            # Log a batch
            losses = {
                "reconstruction": 0.45,
                "kl_divergence": 0.12,
                "adversarial": 0.08,
                "total": 0.65
            }
            
            memory_metrics = {
                "gpu_allocated": 3.2,
                "gpu_reserved": 4.0,
                "cpu_rss": 8.5
            }
            
            throughput_metrics = {
                "samples_per_second": 128.5,
                "tokens_per_second": 8224
            }
            
            data_stats = {
                "files_processed": 32,
                "files_augmented": 12
            }
            
            # Capture log output
            log_file = enhanced_logger.save_dir / "logs" / f"training_{enhanced_logger.experiment_id}.log"
            
            enhanced_logger.log_batch(
                batch=5,
                losses=losses,
                learning_rate=1e-4,
                gradient_norm=1.5,
                throughput_metrics=throughput_metrics,
                memory_metrics=memory_metrics,
                data_stats=data_stats
            )
            
            # Read log file and verify format
            if log_file.exists():
                with open(log_file, 'r') as f:
                    log_content = f.read()
                
                # Check for required elements
                assert "Epoch: 1/10, Batch: 5/50" in log_content, "Should have epoch/batch info"
                assert "Files processed: 32 (12 augmented)" in log_content, "Should have file stats"
                assert "recon: 0.45" in log_content, "Should have reconstruction loss"
                assert "kl: 0.12" in log_content, "Should have KL loss"
                assert "adv: 0.08" in log_content, "Should have adversarial loss"
                assert "GPU 3.20GB/4.00GB" in log_content, "Should have GPU memory"
                assert "RAM: 8.50GB" in log_content, "Should have RAM usage"
                
                print(f"   âœ… Batch logging format correct")
                print(f"   âœ… All required fields present")
                print(f"   âœ… Memory tracking working")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_usage_tracking():
    """Test detailed data usage tracking."""
    print("\nğŸ§ª Testing Data Usage Tracking")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="test_data_usage",
                save_dir=Path(temp_dir),
                model_config={"d_model": 256},
                training_config={"batch_size": 16},
                data_config={"dataset_size": 1000},
                enable_tensorboard=False,
                enable_dashboard=False,
                enable_wandb=False
            )
            
            # Log various data usage scenarios
            test_cases = [
                DataUsageInfo(
                    file_name="piece_001.mid",
                    original_length=512,
                    processed_length=256,
                    augmentation_applied={"pitch_transpose": True, "time_stretch": False},
                    transposition=3,
                    time_stretch=1.0,
                    velocity_scale=0.9,
                    instruments_used=["piano", "violin"],
                    processing_time=0.234,
                    cache_hit=False
                ),
                DataUsageInfo(
                    file_name="piece_002.mid",
                    original_length=1024,
                    processed_length=1024,
                    augmentation_applied={"pitch_transpose": False, "time_stretch": True},
                    transposition=0,
                    time_stretch=1.15,
                    velocity_scale=1.0,
                    instruments_used=["guitar"],
                    processing_time=0.012,
                    cache_hit=True
                ),
            ]
            
            for data_info in test_cases:
                enhanced_logger.log_data_usage(data_info)
            
            # Verify tracking
            tracker = enhanced_logger.experiment_tracker
            assert len(tracker.data_usage_history) == 2, "Should track all data usage"
            
            # Check augmentation tracking
            augmented_count = sum(
                1 for info in tracker.data_usage_history
                if any(info.augmentation_applied.values())
            )
            assert augmented_count == 2, "Should track augmented files"
            
            # Check cache hit tracking
            cache_hits = sum(1 for info in tracker.data_usage_history if info.cache_hit)
            assert cache_hits == 1, "Should track cache hits"
            
            print(f"   âœ… Data usage tracked: {len(tracker.data_usage_history)} files")
            print(f"   âœ… Augmentation tracking: {augmented_count} augmented")
            print(f"   âœ… Cache tracking: {cache_hits} cache hits")
            print(f"   âœ… Detailed file info preserved")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_experiment_tracking():
    """Test experiment tracking and comparison."""
    print("\nğŸ§ª Testing Experiment Tracking")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create tracker
            tracker = ComprehensiveExperimentTracker(
                experiment_name="test_tracking",
                save_dir=Path(temp_dir),
                model_config={"d_model": 512, "n_layers": 12},
                training_config={"batch_size": 32, "learning_rate": 1e-4},
                data_config={"dataset_size": 10000}
            )
            
            # Log some batch metrics
            for epoch in range(2):
                for batch in range(10):
                    tracker.log_batch_metrics(
                        epoch=epoch,
                        batch=batch,
                        total_batches=10,
                        losses={"total": 1.0 - (epoch * 0.1 + batch * 0.01)},
                        learning_rate=1e-4,
                        gradient_norm=1.5,
                        throughput_metrics={"samples_per_second": 100 + batch},
                        memory_metrics={"gpu_allocated": 3.0 + batch * 0.1}
                    )
                
                # Log epoch summary
                summary = EpochSummary(
                    epoch=epoch,
                    start_time=datetime.now(),
                    end_time=datetime.now() + timedelta(minutes=30),
                    duration=1800,
                    losses={"total": 0.9 - epoch * 0.1},
                    validation_losses={"total": 0.85 - epoch * 0.08},
                    files_processed=1000,
                    files_augmented=400,
                    total_tokens=1000000,
                    average_sequence_length=1000,
                    learning_rate=1e-4,
                    gradient_norm=1.5,
                    samples_per_second=105,
                    tokens_per_second=105000,
                    memory_usage={"gpu_allocated": 3.5},
                    model_parameters=100000000,
                    checkpoint_saved=True,
                    is_best_model=(epoch == 1)
                )
                tracker.log_epoch_summary(summary)
            
            # Get experiment summary
            exp_summary = tracker.get_experiment_summary()
            
            # Verify summary contents
            assert exp_summary['experiment_id'] == tracker.experiment_id
            assert exp_summary['total_epochs'] == 2
            assert exp_summary['total_batches'] == 20
            assert 'performance_metrics' in exp_summary
            assert 'data_usage_statistics' in exp_summary
            
            print(f"   âœ… Experiment ID: {exp_summary['experiment_id']}")
            print(f"   âœ… Epochs tracked: {exp_summary['total_epochs']}")
            print(f"   âœ… Best epoch: {exp_summary['performance_metrics']['best_epoch']}")
            
            # Generate comparison report
            report_path = tracker.generate_comparison_report([tracker.experiment_id])
            assert report_path.exists(), "Comparison report should be created"
            
            print(f"   âœ… Comparison report generated")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_eta_calculation():
    """Test training progress ETA calculation."""
    print("\nğŸ§ª Testing ETA Calculation")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="test_eta",
                save_dir=Path(temp_dir),
                model_config={"d_model": 256},
                training_config={"batch_size": 16, "num_epochs": 100},
                data_config={"dataset_size": 1000},
                enable_tensorboard=False,
                enable_dashboard=False,
                enable_wandb=False
            )
            
            # Simulate training progress
            enhanced_logger.start_training(total_epochs=100)
            
            # First epoch - no ETA yet
            enhanced_logger.start_epoch(epoch=1, total_batches=50)
            eta_str = enhanced_logger._calculate_eta()
            assert eta_str == "Calculating...", f"First epoch should show calculating, got: {eta_str}"
            
            print(f"   âœ… Initial ETA: {eta_str}")
            
            # Simulate some progress
            enhanced_logger.training_start_time = datetime.now() - timedelta(minutes=10)
            enhanced_logger.current_epoch = 5
            enhanced_logger.current_batch = 25
            enhanced_logger.total_batches = 50
            
            # Calculate ETA
            eta_str = enhanced_logger._calculate_eta()
            assert "h" in eta_str or "min" in eta_str, f"Should have time unit, got: {eta_str}"
            
            print(f"   âœ… Progress ETA: {eta_str}")
            
            # Test minute calculation
            eta_minutes = enhanced_logger._calculate_eta_minutes()
            assert isinstance(eta_minutes, int), "Should return integer minutes"
            assert eta_minutes > 0, "Should have positive ETA"
            
            print(f"   âœ… ETA in minutes: {eta_minutes}")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_anomaly_detection():
    """Test training anomaly detection."""
    print("\nğŸ§ª Testing Anomaly Detection")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="test_anomaly",
                save_dir=Path(temp_dir),
                model_config={"d_model": 256},
                training_config={"batch_size": 16},
                data_config={"dataset_size": 1000},
                enable_tensorboard=False,
                enable_dashboard=False,
                enable_wandb=False
            )
            
            # Log different types of anomalies
            anomalies = [
                ("gradient_explosion", "Gradient norm exceeded 100.0"),
                ("loss_spike", "Loss increased by 500% in one step"),
                ("training_instability", "Loss oscillating rapidly"),
                ("memory_overflow", "GPU memory usage at 95%"),
            ]
            
            log_file = enhanced_logger.save_dir / "logs" / f"training_{enhanced_logger.experiment_id}.log"
            
            for anomaly_type, details in anomalies:
                enhanced_logger.log_training_anomaly(anomaly_type, details)
            
            # Check log file for anomalies
            if log_file.exists():
                with open(log_file, 'r') as f:
                    log_content = f.read()
                
                assert "[ANOMALY_DETECTED]" in log_content, "Should have anomaly markers"
                
                for anomaly_type, details in anomalies:
                    assert anomaly_type in log_content, f"Should log {anomaly_type}"
                    assert details in log_content, f"Should log details: {details}"
            
            print(f"   âœ… Anomaly detection working")
            print(f"   âœ… {len(anomalies)} anomaly types tested")
            print(f"   âœ… Detailed logging of anomalies")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_sample_generation_logging():
    """Test generated sample logging."""
    print("\nğŸ§ª Testing Sample Generation Logging")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="test_samples",
                save_dir=Path(temp_dir),
                model_config={"d_model": 256},
                training_config={"batch_size": 16},
                data_config={"dataset_size": 1000},
                enable_tensorboard=False,
                enable_dashboard=False,
                enable_wandb=False
            )
            
            # Create sample directory
            sample_dir = enhanced_logger.save_dir / "samples"
            sample_dir.mkdir(exist_ok=True)
            
            # Log generated samples
            for epoch in [10, 20, 30]:
                sample_path = sample_dir / f"sample_epoch_{epoch:03d}.pt"
                
                # Create dummy sample file
                torch.save(torch.randn(1, 256), sample_path)
                
                sample_info = {
                    "sequence_length": 256,
                    "unique_tokens": 128,
                    "repetition_rate": 0.5,
                    "generation_time": 2.34
                }
                
                enhanced_logger.current_epoch = epoch
                enhanced_logger.log_sample_generated(sample_path, sample_info)
            
            # Verify sample tracking
            assert len(enhanced_logger.samples_generated) == 3, "Should track all samples"
            
            # Check log format
            log_file = enhanced_logger.save_dir / "logs" / f"training_{enhanced_logger.experiment_id}.log"
            if log_file.exists():
                with open(log_file, 'r') as f:
                    log_content = f.read()
                
                assert "Samples saved:" in log_content, "Should log sample paths"
            
            print(f"   âœ… Sample generation tracked: {len(enhanced_logger.samples_generated)} samples")
            print(f"   âœ… Sample paths logged correctly")
            print(f"   âœ… Sample metadata preserved")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_tensorboard_integration():
    """Test TensorBoard logging integration."""
    print("\nğŸ§ª Testing TensorBoard Integration")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create TensorBoard logger
            tb_logger = TensorBoardLogger(
                log_dir=Path(temp_dir),
                experiment_id="test_tb",
                comment="Test TensorBoard"
            )
            
            # Log various metrics
            tb_logger.log_training_metrics(
                epoch=1,
                batch=10,
                losses={"reconstruction": 0.5, "kl": 0.1, "total": 0.6},
                learning_rate=1e-4,
                gradient_norm=1.5,
                throughput_metrics={"samples_per_second": 100},
                memory_metrics={"gpu_allocated": 3.5}
            )
            
            # Log epoch summary
            tb_logger.log_epoch_summary(
                epoch=1,
                train_losses={"total": 0.55},
                val_losses={"total": 0.52},
                epoch_duration=1800,
                data_stats={"files_processed": 1000}
            )
            
            # Verify TensorBoard files created
            tb_files = list(Path(temp_dir).rglob("events.out.tfevents.*"))
            assert len(tb_files) > 0, "Should create TensorBoard event files"
            
            print(f"   âœ… TensorBoard logger initialized")
            print(f"   âœ… Event files created: {len(tb_files)}")
            print(f"   âœ… Metrics logged successfully")
            
            # Close logger
            tb_logger.close()
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_console_logging():
    """Test console logging and notifications."""
    print("\nğŸ§ª Testing Console Logging")
    print("-" * 40)
    
    try:
        # Create console logger
        console_logger = ConsoleLogger("test_console")
        
        # Test training progress logging
        console_logger.log_training_progress(
            epoch=5,
            batch=25,
            total_batches=100,
            losses={"total": 0.65, "reconstruction": 0.45},
            throughput={"samples_per_second": 128},
            eta_minutes=45
        )
        
        # Test epoch completion
        console_logger.log_epoch_complete(
            epoch=5,
            duration=1800,
            losses={"total": 0.60}
        )
        
        # Test alerts
        console_logger.log_alert("High GPU memory usage", severity="warning")
        console_logger.log_alert("Training diverged", severity="critical")
        
        print(f"   âœ… Console progress logging working")
        print(f"   âœ… Epoch completion notifications working")
        print(f"   âœ… Alert system working (warning/critical)")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_log_rotation():
    """Test log rotation and compression."""
    print("\nğŸ§ª Testing Log Rotation")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create logger with small rotation size for testing
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="test_rotation",
                save_dir=Path(temp_dir),
                model_config={"d_model": 256},
                training_config={"batch_size": 16},
                data_config={"dataset_size": 1000},
                enable_tensorboard=False,
                enable_dashboard=False,
                enable_wandb=False
            )
            
            # Get the file handler
            for handler in enhanced_logger.structured_logger.handlers:
                if hasattr(handler, 'maxBytes'):
                    # Verify rotation settings
                    assert handler.maxBytes == 100*1024*1024, "Should have 100MB max size"
                    assert handler.backupCount == 5, "Should keep 5 backups"
                    print(f"   âœ… Log rotation configured: 100MB max, 5 backups")
                    break
            
            # Generate some log data to test rotation would work
            for i in range(100):
                enhanced_logger.structured_logger.info(f"Test log entry {i}" * 100)
            
            # Check log files exist
            log_dir = enhanced_logger.save_dir / "logs"
            log_files = list(log_dir.glob("*.log*"))
            assert len(log_files) > 0, "Should have log files"
            
            print(f"   âœ… Log files created: {len(log_files)}")
            print(f"   âœ… Rotation handler active")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_full_logging_integration():
    """Test full logging system integration."""
    print("\nğŸ§ª Testing Full Logging Integration")
    print("-" * 40)
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create enhanced logger with all components
            enhanced_logger = EnhancedTrainingLogger(
                experiment_name="full_integration_test",
                save_dir=Path(temp_dir),
                model_config={
                    "d_model": 512,
                    "n_layers": 12,
                    "vocab_size": 774,
                    "mode": "vae-gan"
                },
                training_config={
                    "batch_size": 32,
                    "learning_rate": 1e-4,
                    "num_epochs": 100,
                    "gradient_accumulation_steps": 4
                },
                data_config={
                    "dataset_size": 50000,
                    "augmentation_enabled": True,
                    "cache_enabled": True
                },
                enable_tensorboard=True,
                enable_dashboard=False,  # No GUI in tests
                enable_wandb=False  # No W&B in unit tests
            )
            
            # Simulate a complete training scenario
            enhanced_logger.start_training(total_epochs=100)
            
            # Log model architecture
            model = Mock()
            model.parameters = Mock(return_value=[torch.nn.Parameter(torch.randn(100, 100))])
            input_sample = torch.randint(0, 774, (1, 64))
            enhanced_logger.log_model_architecture(model, input_sample)
            
            # Simulate 2 epochs
            for epoch in range(1, 3):
                enhanced_logger.start_epoch(epoch=epoch, total_batches=50)
                
                # Simulate batches
                for batch in range(5):  # Just 5 batches for testing
                    # Log data usage
                    data_info = DataUsageInfo(
                        file_name=f"piece_{batch:03d}.mid",
                        original_length=1024,
                        processed_length=512,
                        augmentation_applied={
                            "pitch_transpose": batch % 2 == 0,
                            "time_stretch": batch % 3 == 0
                        },
                        transposition=(-6 if batch % 2 == 0 else 0),
                        time_stretch=(1.1 if batch % 3 == 0 else 1.0),
                        velocity_scale=0.9 + batch * 0.02,
                        instruments_used=["piano"],
                        processing_time=0.1 + batch * 0.01,
                        cache_hit=batch > 2
                    )
                    enhanced_logger.log_data_usage(data_info)
                    
                    # Log batch metrics
                    losses = {
                        "reconstruction": 0.5 - epoch * 0.05 - batch * 0.01,
                        "kl_divergence": 0.1 + batch * 0.005,
                        "adversarial": 0.08 - epoch * 0.01,
                        "total": 0.68 - epoch * 0.06 - batch * 0.005
                    }
                    
                    enhanced_logger.log_batch(
                        batch=batch,
                        losses=losses,
                        learning_rate=1e-4 * (0.9 ** epoch),
                        gradient_norm=1.5 - batch * 0.1,
                        throughput_metrics={
                            "samples_per_second": 100 + batch * 5,
                            "tokens_per_second": 6400 + batch * 320
                        },
                        memory_metrics={
                            "gpu_allocated": 3.0 + batch * 0.2,
                            "gpu_reserved": 4.0,
                            "cpu_rss": 8.0 + batch * 0.1
                        },
                        data_stats={
                            "files_processed": (batch + 1) * 32,
                            "files_augmented": (batch + 1) * 12
                        }
                    )
                
                # Generate sample
                if epoch == 2:
                    sample_path = enhanced_logger.save_dir / f"sample_epoch_{epoch:03d}.pt"
                    torch.save(torch.randn(1, 256), sample_path)
                    enhanced_logger.log_sample_generated(
                        sample_path,
                        {
                            "sequence_length": 256,
                            "unique_tokens": 150,
                            "repetition_rate": 0.41,
                            "generation_time": 3.45
                        }
                    )
                
                # End epoch
                enhanced_logger.end_epoch(
                    train_losses={"total": 0.65 - epoch * 0.05},
                    val_losses={"total": 0.63 - epoch * 0.04},
                    data_stats={
                        "files_processed": 1600,
                        "files_augmented": 600,
                        "total_tokens": 819200,
                        "average_sequence_length": 512,
                        "learning_rate": 1e-4 * (0.9 ** epoch),
                        "gradient_norm": 1.2,
                        "samples_per_second": 120,
                        "tokens_per_second": 61440,
                        "memory_usage": {"gpu_allocated": 3.5},
                        "model_parameters": 100000000
                    },
                    is_best_model=(epoch == 2),
                    checkpoint_saved=True
                )
            
            # Log anomaly
            enhanced_logger.log_training_anomaly(
                "gradient_explosion",
                "Gradient norm = 152.3, clipping to 1.0"
            )
            
            # End training
            enhanced_logger.end_training()
            
            # Verify all outputs
            assert (enhanced_logger.save_dir / "logs").exists(), "Logs directory should exist"
            assert (enhanced_logger.save_dir / "experiments").exists(), "Experiments directory should exist"
            assert (enhanced_logger.save_dir / "tensorboard").exists(), "TensorBoard directory should exist"
            
            # Check experiment summary
            summary = enhanced_logger.get_experiment_summary()
            assert summary['total_epochs'] == 2, "Should have logged 2 epochs"
            assert summary['total_batches'] == 10, "Should have logged 10 batches"
            
            # Check final report
            report_files = list((enhanced_logger.save_dir / "experiments").glob("*_final_report.json"))
            assert len(report_files) > 0, "Should create final report"
            
            print(f"   âœ… Full integration test passed")
            print(f"   âœ… All logging systems working together")
            print(f"   âœ… Experiment tracked: {summary['experiment_id']}")
            print(f"   âœ… Final report generated")
            print(f"   âœ… All directories and files created correctly")
            
            return True
            
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all Phase 4.2 logging system tests."""
    print("ğŸ¯ Phase 4.2 Logging System Test Suite")
    print("=" * 60)
    
    tests = [
        ("Structured Logging Format", test_structured_logging_format),
        ("Enhanced Logger Initialization", test_enhanced_logger_initialization),
        ("Batch-Level Logging", test_batch_logging),
        ("Data Usage Tracking", test_data_usage_tracking),
        ("Experiment Tracking", test_experiment_tracking),
        ("ETA Calculation", test_eta_calculation),
        ("Anomaly Detection", test_anomaly_detection),
        ("Sample Generation Logging", test_sample_generation_logging),
        ("TensorBoard Integration", test_tensorboard_integration),
        ("Console Logging", test_console_logging),
        ("Log Rotation", test_log_rotation),
        ("Full Logging Integration", test_full_logging_integration),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"âŒ {test_name} crashed: {e}")
            results.append((test_name, False))
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š Test Results Summary")
    print("=" * 60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nğŸ“ˆ Overall: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All Phase 4.2 logging system components working correctly!")
        print("ğŸ“Š Comprehensive logging and visualization ready!")
        print("ğŸ” Training transparency achieved with detailed tracking!")
        return True
    else:
        print("ğŸ› ï¸  Some components need fixes before proceeding.")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)